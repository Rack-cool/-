#### 一、LangChain封装本地聊天模型

1、安装库

 	langchain：是一个用于构建对话系统的框架。它提供了许多工具和模块，帮助开发者快速搭建和训练对系统。这个库支持多种语言模型和服务，包括但不限于OpenAI的模型。

 	langchain\_community：是一个社区驱动的扩展库，旨在为langchain提供更多的功能和插件。这个库通常包含由社区贡献的模块和工具，可以帮助开发者更快地实现特定功能。

 	langchain-openai：是专门为langchain框架设计的OpenAI集成库。它提供了与OpenAI API交互的便捷方式，使得在langchain中使用OpenAI的模型变得更加简单。

2、LangChain模型推理

 	LangChain中包含两种语言模型：LLMs（纯文本补全模型）和ChatModels（专门针对对话进行了调整的模型）

3、LangChain部署本地模型方法有两种：

 	方法一：如果你启动vm服务，则vlm提供的api接口与OpenAl接口兼容可以直接使用。

 	方法二：使用手动封装的方式替掉openai(手动封装的效果等于llm.invoke的效果，也就是纯

文本补全)。

4、聊天模型为什么需要特殊符号：

 	这些符号主要是为了帮助模型区分不同的对话方。在多轮对话中，模型需要知道当前的发言人是用户还是系统，或者是自己（助手）。这种明确的角色标记让模型能够更好的理解对话的上下文并做出适当的响应。

#### 二、LangChain-prompt提示词

***1、在大模型应用中，什么是Prompt（提示）？它起什么作用？***

 	Prompt是一种包含文本指令和占位符的模版，用于指导大预言模型（LLM）生成特定类型或格式的输出。它的主要作用是引导和约束模型的行为，使其产生符合预期的回复。

***2、LangChain中的 chatpromptTemplate 主要用于构建什么类型的提示?它通常由哪几种不同角色的消息模板构成?***

ChatPromptTemplate主要用于构建模拟多轮对话场景的结构化提示。它通常由系统消息模板（SystemMessagePromptTemplate）、人类（用户）消息模板（HumanMessagePromptTemplate）和AI（助手）消息模板（AIMessagePromptTemplate）\\\*\\\*组合而成。



***3、在 chatPromptTemplate.from messages(\[...])中，可以直接使用 SystemMessage.HumanMessage 等消息类也可以使用 systemMessagePromptTemplate 等模板类。这两者在使用上的主要区别是什么?***

 	主要区别在于是否包含变量占位符。

 	直接使用消息类（如SystemMessage），其内容是固定的。

 	使用消息模板类（如SystemMessagePromptTemplate）则可以包含占位符（如{variable}），允许在格式化时动态填充内容。

#### 三、LangChain-outputparser输出解释器

***1、在LangChain中，OutputParser(输出解析器)是用来做什么的?为什么它在大模型应用开发中很重要?***

 	OutputParser用于解析大语言模型（LLM）返回的文本结果，将其从非结构化的自然语言转换成程序可用的结构化数据（如列表、字典、对象）。

 	它很重要，因为应用程序通常需要结构化的数据来进行后续的逻辑处理，OutputParser使得从LLM获取可用数据更加方便和可靠。

#### 四、LangChain-chain链

***1、在LangChain中，“链”的主要概念是指？***

 	将多个处理步骤或者组件按顺序连接起来的方式，链的核心是将不同的功能模块串联起来，形成一个处理流程

***2、LangChain中最简单的内置链 LLMchain 是由哪两个基本组件构成的?它实现了什么样的基本流程?***

 	LLMChain 由一个 PromptTemplate（提示模板） 和一个 语言模型（LLM或聊天模型） 构成。

***3、什么是检索增强（RAG）技术？相比单纯的LLM生成，他有什么优势？***

 	RAG是一种将外部知识检索（Retrieval）与LLM的文本生成（Generation）相结合的技术。优势在于，它能让LLM在生成回答时利用检索到的最新、特定领域的外部信息作为上下文，从而生成更准确、更可靠、基于事实的答案，减少“幻觉”。

***4、LangChain中的RetrievalgQA 链是如何实现RAG功能的?它通常依赖哪些组件协同工作?***

 	LangChain中的RetrievalQA链通过标准化流水线实现RAG功能:

 	a、首先使用检索器从向量数据库中查找与问题相关的文档片段，

 	b、然后将这些检索结果作为上下文信息与用户问题一同填入预设的提示模板，

 	c、最后交由语言模型生成基于证据的准确回答。

 	这一流程依赖四个核心组件协同工作:文档加载器负责从多种来源获取原始数据，文本分割器将长文档切分为适合处理的片段，嵌入模型与向量数据库将文本转换为向量并实现相似性检索，提示模板与语言模型则共同完成信息整合与自然语言生成，形成端到端的知识增强问答系统。

#### 五、LangChain-memory记忆

1、什么是memory记忆？

 	memory在LangChain中是用来存储对话状态的组件，通常，在一个复杂的对话系统中，我们需要用户之前说过的话，以便生成上下文相关的回答。

 	LangChain提供了多种类型的memory机制，帮助开发者方便的管理对话历史或其他有状态的信息

2、三种类型：

 	a、conversationbuffermemory：

 	ConversationBufferMemory将所有轮次的对话历史完整地存储在一个缓冲区中。其主要特点是简单直接，保留了全部原始对话信息，但在对话很长时可能会超出模型的上下文长度限制。

 	b、conversationsummarymemory：

 	ConversationSummaryMemory不对对话历史进行完整存储，而是使用一个LLM实时地将对话内容进行总结摘要。它的优势在于能够有效压缩历史信息长度，减少Token消耗，更适合处理非常长的对话。

 	c、conversationbufferwindowsmemory：

 	ConversationBufferWindowMemory通过一个滑动窗口来管理对话历史，只保留最近的k轮对话交互记录。参数k决定了这个窗口的大小，即保留最近对话的数量。

#### 六、LangChain-agent代理

***1、在LangChain中，Agent(代理)和 Chain(链)的主要区别是什么?Agent具备哪些Chain通常不具备的能***

***力?***

Chain通常按照预定义的固定顺序执行组件。



 	Agent则使用LLM进行思考和决策，能够根据输入动态地选择并调用一个或多个工具（Tools），执行顺序不固定，直到任务完成。Agent具备自主规划和工具使用的能力。

2、定义一个LangChain Agent可以使用的Tool时，name，func 和 description 这三个参数分别有什么作用?

 	name是工具的唯一标识名；

 	func是工具实际执行的Python函数；

 	description是描述工具功能和适用场景的文本。

***3、很多LangChain Agent是基于ReAct框架实现的，请简述ReAct框架的工作流程(包含哪些关键步骤)？***

 	ReAct框架的工作流程是思考（Thought）-> 行动（Action）-> 行动输入（Action Input）-> 观察（Observation）的循环。Agent先思考该做什么，决定调用哪个工具及输入，执行后得到结果（观察），再根据结果进行下一步思考，直至产生最终答案（Final Answer）。

***4、在创建基于ReAct框架的Agent时，为什么通常需要设置 stop\_sequence 参数(例\["\\nobservation:"」)?***

因为ReAct流程需要Agent（LLM）在输出Action和Action Input后暂停，以便框架能解析这些信息并执行相应的Tool。设置stop\\\_sequence就是告诉LLM在生成到这个特定标记（如换行+Observation:）时停止输出，让框架接管执行Tool。



#### 七、RAG的介绍

1、什么是RAg？它的核心工作机制是什么？

 	RAG（Retrieval-Augmented Generation，检索增强生成）是一种将信息检索技术与大语言模型生成能力相结合的先进框架，其核心工作机制是通过从外部知识源实时检索相关信息来增强生成过程的准确性与事实性

 	其核心工作机制是通过从外部知识源实时检索相关信息来增强生成过程的准确性与事实性。具体而言，RAG首先将用户查询转化为检索指令，从预设的向量化知识库中召回最相关的文档片段；随后，将这些检索结果与原始查询整合为增强提示上下文，交由语言模型进行理解与生成，最终输出基于权威信源、可信度高的回答。

 	RAg更像是给了模型一个知识外挂，模型在回答问题时不在是胡编乱造，而是从已经给出的外部知识库查找相关信息，然后根据查到的信息来组织答案

2、RAg模型通常包括两个主要组件：

 	检索器：检索器负责从大型外部知识库中找到当前任务或问题相关的文档，它通常使用诸如Elasticsearch或基于嵌入的向量搜索，（FAISS）来检索最相关的信息。知识库可以是任何形式的文本库，包括维基百科，公司内部文档，技术文档等

 	生成器：生成器是基于预训练的大规模语言模型，负责顾根据检索到的信息生成自然语言的回答或文本，生成器不仅依赖与模型本身的内部知识（即在训练过程中学到的知识）。还结合了从检索器获得的外部信息来生成更具有上下文喝准确性的答案。

#### 八、RAG的文本加载

***1、在LangChain RAG流程中，Document Loader(文档加载器)承担的首要任务是什么?***



 	首要任务是从不同的数据源（如TXT, PDF, CSV等文件）加载原始数据，并将这些数据转换成LangChain统一的Document对象格式，为后续的文本处理（如分割、嵌入）做准备。

***2、LangChain中用于表示加载后数据的 Document 对象，其结构通常包含哪两个主要部分?分别是什么含义?***

 	包含两个主要部分：page\_content 和 metadata。page\_content 存储文档的实际文本内容。metadata 是一个字典，存储文档的元数据信息。

***3、使用 PyPDFLoader 加载PDF文档时，调用 .load\_and\_split()方法有什么特点?这对于后续处理有什么好处?***

 	特点是它会将PDF按页分割，每一页生成一个Document对象，并在metadata中记录页码。好处是直接获得了以页为单位的文档块，方便后续按页进行信息检索或处理。

***4、在使用 unstructuredMarkdownLoader 加载Markdown文件时，设置 mode="elements"有什么作用?***

设置mode="elements"可以使加载器根据Markdown的语义结构（如标题、段落）来切分文档，生成多个Document对象。

#### 九、RAG的文本分割

***1、在RAG系统中，为什么需要对加载的原始文档进行文本分割?至少说出两点理由？***

&nbsp;	1、提升检索效率：是文本分割的首要原因，对于较长的文档，将其分成多个片段或片段，这样每个片段可以单独进行检索，从而提高检索的精度和速度

&nbsp;	2、更好的信息匹配：当文档被合理地分割后，检索算法可以更加精确的匹配用户查询和文档片段，不仅能减少噪声，还可以确保检索到的内容更加相关

&nbsp;	3、增强生成质量：文本分割可以确保每个文档片段足够独立，且能够提供完整的上下文信息，从而提高生成的准确性和上下文连贯性

&nbsp;	4、降低计算复杂度：减少模型计算量，提高响应速度，不仅优化了模型的性能，还减少了生成结果的延迟。

***2、LangChain中的 RecursivecharacterTextsplitter 相比 characterTextsplitter 的主要优势是什么?它是如何工作的?***

	主要优势是分割方式更智能、更灵活。它会按优先顺序尝试用一组不同的分隔符（如段落、句子、空格）进行递归分割，尽可能保持语义单元（如句子）的完整性，而不是简单地按单一字符切分。

***3、文本分割器中的 chunk\_over1ap 参数有什么作用?为什么设置重叠通常是有益的?***

&nbsp;	chunk\_overlap参数用于指定相邻文本块之间共享（重叠）的字符数。设置重叠是有益的，因为它有助于保持分割点附近的上下文连续性，避免重要信息在块的边界处被完全切断，从而利于后续的检索和理解。

***4、RecursivecharacterTextsplitter 默认的分隔符列表可能不适合中文文本，需要如何调整以获得更好的中文分割效果?***

&nbsp;	需要在separators参数中加入中文常用的标点符号作为分隔符，例如句号。、逗号，、空格 等，并可以调整它们的优先级顺序，使得分割器优先在这些标点处切分。

***5、除了通用的按字符或递归字符分割，LangChain还提供了针对特定文档格式的分割器，例如这类分割器有什么优点?MarkdownHeaderTextSplitter***

&nbsp;	优点在于能够利用文档自身的结构信息（如Markdown的标题 # ##）来进行分割。这样得到的文本块语义更连贯，并且可以在元数据（metadata）中保留原始的结构信息（如所属章节标题），有助于更精准地检索和组织信息。

6、三种方法：

&nbsp;	1、字符分割：按照特定字符分割，如默认值换行符“\\n\\n”

&nbsp;	2、递归字符分割：递归字符文本分割是字符分割的升级版，它以字符分割为基础，但在分割时引入了递归的机制。

&nbsp;	3、特定文档的分割：特定文档分割是基于文档结构对文本进行分割的一种方式。不同的文档类型通常有各自的结构化信息，例如书籍中的章节和段落、网页中的HTML标签等。利用这些预定义的结构化信息，可以更加自然地分割本,保证片段的上下文连贯性。 

#### 十、常见向量库数据库的介绍

1、什么是向量数据库？

&nbsp;	向量数据库是一种专门用于存储和査询高维向量的数据库。随着机器学习和深度学习技术的发展，向量表示(如词向量、图像特征、用户行为向量等)变得越来越重要。这些向量通常是多维的，表示数据的特征和属性。

&nbsp;	在这样的背景下，向量数据库提供了高效的存储、检索和相似度搜索功能。

向量数据库其实和其他数据库差不多，只不过他存的是向量。

&nbsp;	一般使用向量数据库的流程是:创建数据库->创建集合->创建索引->插入数据->搜索。

***2、常见的向量数据库：***

&nbsp;	1、Pinecone库：全托管的云端向量数据库服务

&nbsp;	2、FAISS库：用于高效相似性搜索和稠密向量聚类的开源库

&nbsp;	3、Chorma库：轻量级、嵌入式的开源向量数据库

&nbsp;		4、Milvus库：云原生的、高性能的开源向量数据库

***3、为什么在构建RAG(检索增强生成)系统时，向量数据库是一个关键组件?***

	因为RAG需要根据用户查询（转换成向量）快速地从大量文档（也转换成向量）中找到语义最相关的部分作为上下文提供给LLM。向量数据库专门优化了这种大规模向量的相似度搜索过程，能够高效、准确地完成检索任务。

***4、在向量数据库中进行相似度搜索，一般需要经历哪些基本步骤?***

	数据向量化 -> 建库/索引 -> 入库 -> 查询向量化 -> 搜索。

***5、请简述开源库Faiss和云服务Pinecone在作为向量存储和检索方案时的主要区别。***

&nbsp;	Faiss是一个本地库，提供高效的相似度搜索算法和索引结构，开发者需要自己集成和管理。Pinecone是一个托管的云服务（DBaaS），提供了完整的数据库管理功能和易用的API，用户无需关心底层运维。

***6、衡量两个向量相似度时常用的余弦相似度(Cosine Similarity)是基于什么原理?它的值域和含义是什么?***

	余弦相似度基于计算两个向量之间夹角的余弦值。它的值域是 \[-1, 1]。值越接近1，表示两个向量的方向越相似；越接近-1表示方向越相反；接近0表示方向接近正交（不相关）。



